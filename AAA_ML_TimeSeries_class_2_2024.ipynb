{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Академия Аналитиков Авито"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML для аналитиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Занятие №16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- На предыдущих занятиях вы "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Научились тестировать на наличие автокорреляции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Узнали что такое стационарность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Познакомились с `SARIMAX` моделью\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T16:54:50.783143Z",
     "start_time": "2020-10-27T16:54:50.778141Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf \n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "\n",
    "# Модельки\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# Тесты\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf\n",
    "\n",
    "import prophet as fp \n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import graph_objs as go\n",
    "\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "\n",
    "\n",
    "# инициализируем plotly\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "pd.set_option('display.max_columns', None) # Чтобы показывались все колонки\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T15:31:50.793658Z",
     "start_time": "2020-10-27T15:31:50.788648Z"
    }
   },
   "outputs": [],
   "source": [
    "def adf_test(timeseries):\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput, '\\n Null Hypothesis: The series has a unit root.')\n",
    "    \n",
    "def kpss_test(timeseries):\n",
    "    print ('Results of KPSS Test:')\n",
    "    kpsstest = kpss(timeseries, regression='c', nlags=\"auto\")\n",
    "    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','Lags Used'])\n",
    "    for key,value in kpsstest[3].items():\n",
    "        kpss_output['Critical Value (%s)'%key] = value\n",
    "    print (kpss_output, '\\n Null Hypothesis: The process is trend stationary.')\n",
    "    \n",
    "# опишем функцию, которая будет визуализировать все колонки dataframe в виде line plot\n",
    "def plotly_df(df, title = ''):\n",
    "    data = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        trace = go.Scatter(\n",
    "            x = df.index,\n",
    "            y = df[column],\n",
    "            mode = 'lines',\n",
    "            name = column\n",
    "        )\n",
    "        data.append(trace)\n",
    "\n",
    "    layout = dict(title = title, template='plotly_white')\n",
    "    fig = dict(data = data, layout = layout)\n",
    "    iplot(fig, show_link=False)\n",
    "    \n",
    "# Функция для получения данных 'mdape', 'mape', 'mtape' для модели по методу имитированных исторических прогнозов\n",
    "def perf_metrics_d(fp_model):\n",
    "    fp_df_cv = cross_validation(fp_model, initial='730.25 days', period='180 days', horizon = '180 days', parallel=\"processes\")\n",
    "    res = performance_metrics(fp_df_cv,rolling_window = 1)\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План\n",
    "- Prophet (базовая модель)\n",
    "    - Формат подаваемых данных \n",
    "    - Базовая модель и параметры по умолчанию \n",
    "    - Декомпозиция временного ряда на составляющие\n",
    "- Ошибка прогноза и кросс-валидация\n",
    "    - Типы ошибок\n",
    "    - Кросс-валидация\n",
    "- Prophet (гипертюнинг параметров)\n",
    "    - Точки изменения тренда\n",
    "    - Сезонные компоненты\n",
    "    - Эффекты праздников\n",
    "    - Добавление экзогенной переменной\n",
    "    - Подбор параметров\n",
    "- Random Forest\n",
    "    - Feature Engineering\n",
    "    - Подбор параметров\n",
    "    - Фит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet (базовая модель)\n",
    "### Формат подаваемых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Документация**](https://facebook.github.io/prophet/docs/quick_start.html#python-api)\n",
    "\n",
    "\n",
    "[**Данные с прошлого занятия: продажи магазинов Kaggle**](https://www.kaggle.com/competitions/playground-series-s3e19/data)\n",
    "\n",
    "Данные о продажах в различных *вымышленных* обучающих модулей из *вымышленных* магазинов под брендом Kaggle в разных (*настоящих*) странах. Этот набор данных полностью синтетический, но содержит множество эффектов, которые вы видите в реальных данных, например, эффект выходных и праздников, сезонность, ковид и так далее. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение и обработка исходных данных.\n",
    "sales_train_raw = pd.read_csv('train_data.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train = pd.pivot_table(sales_train_raw, index='date', values='sales', aggfunc=sum).reset_index()\n",
    "sales_train.columns = ['ds', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_horizon = 180\n",
    "data = sales_train[sales_train['ds']<=(max(sales_train['ds']) - datetime.timedelta(days=validation_horizon))]\n",
    "data_evaluation = sales_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на первоначальные данные\n",
    "plotly_df(data.set_index('ds')[['y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход принимается dataframe с двумя колонками:\n",
    "- ds — время, поле должно быть типа date или datetime,\n",
    "- y — числовой показатель, который мы хотим предсказывать.\n",
    "\n",
    "Это условные обозначения, принятые в prophet. Использование каких–либо других имен приведет к ошибке при вызове соответствующих функций. Мы уже заранее подготовили нужный нам кусочек данных с правльным названием колонок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:03:18.349308Z",
     "start_time": "2020-10-26T23:03:18.343306Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовая модель и параметры по умолчанию\n",
    "\n",
    "Модель прогнозирования Prophet - это модель прогнозирования временных рядов, предназначенная для работы с общими для бизнеса *особенностями* временных рядов (множественные сезонности, изменения тренда, праздники). \n",
    "\n",
    "<img src= \"https://facebookexperimental.github.io/Robyn/img/prophet_decomp.png\" width=\"50%\" >\n",
    "\n",
    "\n",
    "В основе этой методологии лежит процедура подгонки аддитивных регрессионных моделей со следующими четырьмя основными компонентами: \n",
    "\n",
    "**$$y(t) = g(t) + s(t) + h(t) + \\varepsilon_t$$**\n",
    "\n",
    "- **Тренд $g(t)$** — это кусочно-линейная или кусочная логистическая кривая роста. С линейной кривой все понятно. Логистическая же функция вида $g(t) = \\frac{C}{1+\\exp(-k(t-b))}$ позволяет моделировать рост с насыщением, когда при увеличении показателя снижается темп его роста.\n",
    "\n",
    "\n",
    "- **Сезонные компоненты $s(t)$** отвечают за моделирование периодических изменений, связанных с недельной и годовой сезонностью. Моделируются [рядами Фурье](https://ru.wikipedia.org/wiki/%D0%A0%D1%8F%D0%B4_%D0%A4%D1%83%D1%80%D1%8C%D0%B5).\n",
    "\n",
    "\n",
    "- **Компонента $h(t)$** отвечает за заданные пользователем **праздники и аномальные периоды**, то есть периоды непредсказуемого поведения метрики. \"Праздниками\" в FBProphet являются в том числе и нерегулярные периоды, дни акций, период COVID19 тоже можно отразить в данной компоненте. Праздники представлены в виде dummy variables.\n",
    "\n",
    "\n",
    "- **Ошибка $\\textbf{$\\varepsilon_t$}$** - нормально распределенные случайные процессы. Компонента содержит информацию, которая не учтена моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Рассмотрим четыре шага для прогноза с помощью базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:03:26.045454Z",
     "start_time": "2020-10-26T23:03:18.773305Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Создадим объект класса Prophet (все параметры модели задаются в конструкторе класса, используем дефолтные)\n",
    "m = fp.Prophet()\n",
    "\n",
    "# 2. Проведем обучение\n",
    "m.fit(data)\n",
    "\n",
    "# 3. Cоздадим таблицу с датами, охватывающими даты истории + \"горизонт\" для прогнозирования\n",
    "future = m.make_future_dataframe(periods=validation_horizon)\n",
    "\n",
    "# 4. Получим предсказания на датах, полученных в предыдщуем шаге\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:03:26.076454Z",
     "start_time": "2020-10-26T23:03:26.049453Z"
    }
   },
   "outputs": [],
   "source": [
    "# forecast - это таблица pd.DataFrame, в которой хранятся значения рассчитанных на основе модели m величин\n",
    "# Включены тренд, сезонные компоненты модели, предсказанные значения, а также верхние и нижние границы доверительных интервалов\n",
    "\n",
    "# Вот так выглядят первые несколько предсказанных значений метрики и их (принятые по умолчанию) 80%-ные доверительные границы:\n",
    "forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:03:27.092454Z",
     "start_time": "2020-10-26T23:03:26.080455Z"
    }
   },
   "outputs": [],
   "source": [
    "# Встроенный метод для отображения прогноза\n",
    "# Отражается с 80% интервалом неопределенности (зависящий от тренда и шума)\n",
    "fig1 = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Декомпозиция временного ряда на составляющие\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно отразить компоненты прогноза \n",
    "# По умолчанию вы увидите тренд, годовую сезонность и недельную сезонность временного ряд\n",
    "# Если вы включите праздники, вы увидите их здесь\n",
    "\n",
    "fig2 = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Давайте же оценим качество нашей базовой модели, посчитав ошибку MAPE. \n",
    "- Напомню, что в прошлый раз мы получили следующие результаты MAPE для моделей семейства SARIMAX:\n",
    "    - Model ARIMA MAPE is ..\n",
    "    - Model SARIMAX MAPE is ..\n",
    "    - **Model SARIMA MAPE is ..**\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем формат для джойна табличек\n",
    "data_evaluation['ds'] = pd.to_datetime(data_evaluation['ds'])\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "data_w_error = data_evaluation.merge(forecast[['ds','yhat']], on = ['ds'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем ошибку\n",
    "data_w_error['mape'] = abs(data_w_error['y'] - data_w_error['yhat'])/data_w_error['y']\n",
    "\n",
    "\n",
    "print('Prophet MAPE is: ', np.mean(data_w_error[data_w_error['ds']>max(data['ds'])]['mape']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_error.columns=['ds','y', 'forecast_p','mape']\n",
    "data_w_error.loc[data_w_error['ds']<=max(data['ds']),'forecast_p'] = np.nan\n",
    "data_w_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predicted_class_15 = pd.read_csv('data_predicted_class_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sarima_prophet = data_predicted_class_15.merge(data_w_error[['forecast_p']], left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_df(data_sarima_prophet[['y_validation','forecast_arima','forecast_x','forecast_s','forecast_p']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Видно, что Prophet справился с задачей сильно лучше, чем SARIMA\n",
    "- Но какие еще виды ошибок есть? Как более честно сравнить две модели? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ошибка прогноза и кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Типы ошибок\n",
    "\n",
    "- Ошибки, зависящие от масштаба: \n",
    "$$\\text{ Mean absolute error: }  MAE = mean(|y_t - \\hat{y_t}|)$$\n",
    "$$\\text{ Root mean squared error: }  RMSE = \\sqrt{mean(y_t - \\hat{y_t})^2}$$\n",
    "\n",
    "- При этом, важно сказать, что RMSE стремится сократить **среднее** расстояние между точками, а MAE - **медианное** расстояние. Соответственно RMSE сильнее штрафует более сильные отклонения факта от прогноза, чем MAE. \n",
    "\n",
    "- Приведем приимер:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(time, values, label):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(time, values)\n",
    "    plt.xlabel(\"Time\", fontsize=20)\n",
    "    plt.ylabel(\"Value\", fontsize=20)\n",
    "    plt.title(label, fontsize=20)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_seas = 0\n",
    "neg_seas = 5\n",
    "error_std = 50\n",
    "\n",
    "def gen_ts(pos_seas,neg_seas,error_std, trend=True):\n",
    "    # Just a random pattern\n",
    "    time = np.arange(50)\n",
    "    values_hat = np.where(time < 10, (time+pos_seas)**3, np.where(time>45, -(time+neg_seas)**2, time*2 ))\n",
    "    # Repeat the pattern 5 times\n",
    "    seasonal_hat = []\n",
    "    for i in range(5):\n",
    "        for j in range(50):\n",
    "            seasonal_hat.append(values_hat[j])\n",
    "\n",
    "    noise_hat = np.random.normal(loc = 0, scale = error_std, size = 250)\n",
    "    seasonal_hat += noise_hat\n",
    "    if trend==True:\n",
    "        seasonal_trend_hat = seasonal_hat + np.arange(250)*5\n",
    "    else: \n",
    "        seasonal_trend_hat = seasonal_hat\n",
    "    \n",
    "    return seasonal_trend_hat\n",
    "\n",
    "\n",
    "df_gen = pd.concat([pd.Series(np.arange(250), name = 'ds'),\n",
    "                       pd.Series(np.ravel(gen_ts(pos_seas,neg_seas,error_std)), name = 'y')], axis=1)\n",
    "        \n",
    "        \n",
    "\n",
    "plotly_df(df_gen.set_index('ds'))        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = pd.concat([pd.Series(np.arange(250), name = 'ds'),\n",
    "                    pd.Series(np.ravel(gen_ts(0,9,50)), name = 'y'),\n",
    "                    pd.Series(np.ravel(gen_ts(5,10,100)), name = 'yhat')], axis=1)    \n",
    "\n",
    "plotly_df(df_gen.set_index('ds'))        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['AE'] = np.abs(df_gen['yhat']-df_gen['y'])\n",
    "df_gen['SE'] = (df_gen['yhat']-df_gen['y'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_df(df_gen.set_index('ds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE: ', np.mean(np.abs(df_gen['yhat']-df_gen['y'])))\n",
    "print('RMSE: ', np.sqrt(np.mean((df_gen['yhat']-df_gen['y'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos_seas in [1,2,3,4,5]:\n",
    "    \n",
    "    df_gen = pd.concat([pd.Series(np.arange(250), name = 'ds'),\n",
    "                    pd.Series(np.ravel(gen_ts(0,9,50)), name = 'y'),\n",
    "                    pd.Series(np.ravel(gen_ts(pos_seas,12,100)), name = 'yhat')], axis=1) \n",
    "\n",
    "    mae = np.mean(np.abs(df_gen['yhat']-df_gen['y']))\n",
    "    rmse = np.sqrt(np.mean((df_gen['yhat']-df_gen['y'])**2))\n",
    "    \n",
    "    print('for pos_seas = {}, MAE: {}, RMSE: {}, difference: {}'.format(pos_seas,mae,rmse, rmse-mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ошибки, не зависящие от масштаба: \n",
    "\n",
    "$$\\text{ Mean absolute percentage error: }  MAPE = mean(\\frac{|y_t - \\hat{y_t}|}{y_t})$$\n",
    "\n",
    "- Несмотря на свою привлекательность, у МАPE есть два явных минуса:\n",
    "\n",
    "    - если значния $y_t$ колеблются около нуля, ошибка сильно завышается или же вообще не может быть посчитана.\n",
    "\n",
    "    - MAPE обычно сильно выше для случаев, когда прогноз переоценивает метрику (Прогноз > Факт), так как в знаменателе MAPE стоит именно фактическая метрика. Из этого следует ограниченность MAPE снизу, те при условии прогноза выше нуля, максимальная ошибка \"снизу\" будет 100%. \"Сверху\" же MAPE никак не ограничивает метрику, соответственно ошибка может стремиться к бесконечности.\n",
    "    \n",
    "- Приведем пример: \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = pd.concat([pd.Series(np.arange(250), name = 'ds'),\n",
    "                    pd.Series(np.ravel(gen_ts(0,-45,50, trend=False)/800), name = 'y'),\n",
    "                    pd.Series(np.ravel(gen_ts(1,-45,20, trend=False)/800), name = 'yhat')], axis=1)    \n",
    "\n",
    "plotly_df(df_gen.set_index('ds'))        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['APE'] = np.abs(df_gen['yhat']-df_gen['y'])/df_gen['y']\n",
    "plotly_df(df_gen.set_index('ds'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = pd.concat([pd.Series(np.arange(250), name = 'ds'),\n",
    "                    pd.Series(np.ravel(gen_ts(0,-30,20, trend=True)+200), name = 'y'),\n",
    "                    pd.Series(np.ravel(gen_ts(-1.5,-45,20, trend=True)+200), name = 'yhat')], axis=1)    \n",
    "\n",
    "df_gen['y_yhat_diff'] = abs(df_gen['y']-df_gen['yhat'])\n",
    "\n",
    "plotly_df(df_gen.set_index('ds'))        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['APE'] = np.abs(df_gen['yhat']-df_gen['y'])/df_gen['y']\n",
    "plotly_df(df_gen.set_index('ds'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Чтобы исправить эту проблему, можно использовать следующие типы ошибок: \n",
    "\n",
    "$$\\text{ Median absolute percentage error: }  MDAPE = median(\\frac{|y_t - \\hat{y_t}|}{y_t})$$\n",
    "\n",
    "$$\\text{ Mean absolute scaled error: }  MASE = mean(\\frac{y_t - \\hat{y_t}}{\\frac{1}{T-1}\\sum^T_{t=2}|y_t-y_{t-1}|})$$ \n",
    "\n",
    "$$\\text{ Mean absolute scaled error (for seasonal data): }  MASE = mean(\\frac{y_t - \\hat{y_t}}{\\frac{1}{T-m}\\sum^T_{t=m+1}|y_t-y_{t-m}|})$$\n",
    "\n",
    " $$\\text{ Symmetric mean absolute percentage error: }  SMAPE = mean(\\frac{2*|y_t - \\hat{y_t}|}{y_t+ \\hat{y_t}})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Проверим, как работают эти ошибки\n",
    "\n",
    "- MDAPE\n",
    "\n",
    "$$\\text{ Median absolute percentage error: }  MDAPE = median(\\frac{|y_t - \\hat{y_t}|}{y_t})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_df(df_gen.set_index('ds'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = np.mean(df_gen['APE'])\n",
    "mdape = np.median(df_gen['APE'])\n",
    "\n",
    "print('MAPE: {}, MDAPE: {}'.format(mape,mdape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MDAPE действительно помогло сократить ошибку до \"нормального\" уровня, однако стоит быть очень осторожным, ведь MDAPE не учитывает совсем периоды, в которые прогноз сильно отличается от факта. \n",
    "- Рекомендуется сравнивать MAPE и MDAPE скорее для случаев, когда хочется обнаружить такие периоды. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MASE\n",
    "\n",
    "$$\\text{ Mean absolute scaled error (for seasonal data): }  MASE = mean(\\frac{|y_t - \\hat{y_t}|}{\\frac{1}{T-m}\\sum^T_{t=m+1}|y_t-y_{t-m}|})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mase = np.mean(np.abs(df_gen['y']-df_gen['yhat']))/np.mean(np.abs(df_gen['y']-df_gen['y'].shift(50)))\n",
    "print('MASE: ', mase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ключевое отличие MASE от MAPE заключается в том, что MASE сравнивает полученный прогноз с, так называемым, наивным прогнозом (naive forecast): \n",
    "    - Наивный прогноз - это простое повторение последнего наблюдения в качестве прогноза на будущие периоды: $y_{t} = \\hat{y_{t-1}}$.\n",
    "    - Для сезональных данных наивным прогнозом будет являться повторение последнего наблюдения из предыдущего сезона: $y_{t}= \\hat{y_{t-m}}$\n",
    "    \n",
    "    \n",
    "- Таким образом, знаменателем MASE является MAE для наивного прогноза, а не фактическое значение, как в MAPE. Соответственно, MASE не подвержен тем проблемам, которые есть у MAPE, однако и смысл у MASE другой. \n",
    "\n",
    "\n",
    "- MASE > 1 означает, что ошибка выбранного прогноза больше, чем ошибка наивного прогноза, те выбранный прогноз хуже, чем наивный. MASE < 1, соответственно, говорит об обратном.\n",
    "- Сравнивая несколько моделей, модель с наименьшим MASE является наилучшей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMAPE \n",
    "\n",
    " $$\\text{ Symmetric mean absolute percentage error: }  SMAPE = mean(\\frac{2*|y_t - \\hat{y_t}|}{y_t+ \\hat{y_t}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_df(df_gen.set_index('ds'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['smape'] = 2*np.abs(df_gen['yhat']-df_gen['y'])/(df_gen['y']+df_gen['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_df(df_gen.set_index('ds'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = np.mean(df_gen['APE'])\n",
    "mdape = np.median(df_gen['APE'])\n",
    "smape = np.mean(df_gen['smape'])\n",
    "\n",
    "print('MAPE: {}, MDAPE: {}, SMAPE: {}'.format(mape,mdape,smape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Можно заметить, что за счет наличия факта и прогноза в числителе, SMAPE частично сглаживает аномальные негативные отклонения факта от прогноза, однако не по прежнему имеет тенденцию завышать ошибку для значений близких к нулю. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В рамках нашего курса мы все же чаще будем опираться на MAPE и MDAPE, так как для нас одинково критично завысить или занизить прогноз. Сравнивая MDAPE и MAPE мы будем пытаться привести их к схожим значениям. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация\n",
    "\n",
    "- Окей, мы изучили кучу разных типов ошибок, поняли, чем они отличаются и попробовали оценить качество модели методом Out Of Sample (OOS). Однако, тру саентисты скажут, что модель может сильно переобучиться в момент обучения, соответственно и OOS ошибка может быть сильно занижена.\n",
    "\n",
    "- И тру саентисты будут правы) Как известно от переобучения есть одно простое средство: кросс-валидация, которая работает немного особенным способом в Time-series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- При работе с временными рядами применяют несколько модификаций классической кросс-валидации. Чаще всего различают **rolling-window cross-valiadation** (A) и **expanding window cross-validation** (B) . В пакете fbrophet, в частности, реализован метод expanding window (Simulated Historical Forecasts, SHF).\n",
    "\n",
    "![image.png](https://www.researchgate.net/profile/Alireza-Shojaei/publication/326380749/figure/fig1/AS:647993657159681@1531505135948/Visual-represenation-of-cross-validation-methods-used-A-Evaluation-based-on-a-fixed.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Expanding window может применяться чаще, когда ряд имеет ярко выраженный сезонный паттерн и стабильный тренд, так как в этом случае первые наблюдения ряда содержат потенциальную информацию о будущих значениях. \n",
    "\n",
    "- Rolling window полезно, когда у нас довольно волатильный ряд или когда наиболее недавняя история более важна для прогнозирования (высокая корреляция с наиболее недавними лагами).\n",
    "\n",
    "Expanding window            |  Rolling window\n",
    ":-------------------------:|:-------------------------:\n",
    "![](https://robotwealth.com/wp-content/uploads/2020/05/sma_viz_expanding-1.gif)  |  ![](https://robotwealth.com/wp-content/uploads/2020/05/sma_viz_rolling2.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция FBProphet <code>cross_validation()</code> принимает следующие параметры:\n",
    "\n",
    "- <code>initial</code> (\"начальный отрезок\") - исторические наблюдения за initial дней , образуют обучающие данные для подгонки соответствующей модели (по умолчанию составляет 3×H)\n",
    "\n",
    "\n",
    "- <code>horizon</code> (\"горизонт прогноза\") - следующие за initial H точек наблюдений, для которых строится прогноз\n",
    "\n",
    "\n",
    "- <code>period</code> - период, на который увеличивается initial перед следующим прогнозом (по умолчанию составляет H/2)\n",
    "\n",
    "\n",
    "<img src= \"https://i.ibb.co/nsbjc6k/2023-04-04-16-04-49.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cv = cross_validation(m, initial='730.5 days', period='180 days', horizon = '180 days', parallel=\"processes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# результатом кросс-валидации является таблица с тренировочными данными за исключением периода initial, \n",
    "# однако теперь для каждого наблюдения подсчитан прогноз\n",
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция performance_metrics подсчитывает основные виды ошибок. параметр rolling_window отвечает за долю наблюдений\n",
    "# в фолде на основе которых подсчитывается ошибка. Мы используем все данные фолда для подсчета ошибки. \n",
    "res = performance_metrics(df_cv,rolling_window = 1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_metrics = perf_metrics_d(m)\n",
    "\n",
    "print(f\"Performance metrics of model:\\nMDAPE = {round(pb_metrics.at[0,'mdape'],4)}\\nMAPE = {round(pb_metrics.at[0,'mape'],4)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем формат для джойна табличек\n",
    "data_evaluation['ds'] = pd.to_datetime(data_evaluation['ds'])\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "data_w_error = data_evaluation.merge(forecast[['ds','yhat']], on = ['ds'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_error['APE'] = abs(data_w_error['y']-data_w_error['yhat'])/data_w_error['y']\n",
    "\n",
    "plotly_df(data_w_error.set_index('ds')[['y', 'yhat','APE']], title = 'Fact vs Forecast')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet (гипертюнинг параметров)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Полный список параметров модели FBProphet c описанием.](https://facebook.github.io/prophet/docs/diagnostics.html)\n",
    "\n",
    "Все параметры отвечают за каждый из компонентов FBProphet: \n",
    "- Trend\n",
    "    - **changepoint_prior_scale**\n",
    "    - **changepoint_range**    \n",
    "    - growth \n",
    "    - changepoints\n",
    "    - n_changepoints\n",
    "\n",
    "- Seasonality\n",
    "    - **seasonality_prior_scale**\n",
    "    - **seasonality_mode**  \n",
    "    - yearly_seasonality \n",
    "    - weekly_seasonality\n",
    "\n",
    "- Holidays\n",
    "    - **holidays**\n",
    "    - **holidays_prior_scale** \n",
    "  \n",
    "В документации Профета рекомендуется настраивать именно параметры, выделенные жирным. Разберем их подробнее:\n",
    "\n",
    "- **changepoint_prior_scale** — параметр, задающий чувствительность автоматического механизма обнаружения точек излома в тренде временного ряда y (0.05 по умолчанию). Более высокие значение позволят иметь больше таких точек излома (что одновременно увеличит риск переобучения модели)\n",
    "\n",
    "- **changepoint_range** — доля исторических данных (начиная с самого первого наблюдения), по которым будут оценены точки излома. По умолчанию составляет 0.8 (т.е. 80% наблюдений)\n",
    "\n",
    "- **seasonality_prior_scale** — параметр, определяющий выраженность сезонных компонент модели (10 по умолчанию). Более высокие значения приведут к более “гибкой” модели, а низкие — к модели со слабее выраженными сезонными эффектами. Этот параметр можно задать отдельно для каждого типа сезонности с помощью функции add_seasonality()\n",
    "\n",
    "- **seasonality_mode** — режим моделирования сезонных компонент. Принимает два возможных значения: 'additive' (аддитивный, задан по умолчанию) и 'multiplicative' (мультипликативный)\n",
    "\n",
    "- **holidays** — таблица, содержащая два обязательных столбца: holiday (текстовая переменная с названиями \"праздников\") и ds (даты). По желанию в такую таблицу можно добавить еще два столбца — *lower_window* и *upper_window*, которые задают отрезок времени вокруг соответствующего события. Так, например, при \"lower_window = -2\" в модель будут добавлены 2 дня, предшествующие соответствующему событию\n",
    "\n",
    "- **holidays_prior_scale** — параметр, определяющий выраженность эффектов 'праздников' и других важных событий (10 по умолчанию)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точки изменения тренда\n",
    "\n",
    "[Почитать подробнее в доках](https://facebook.github.io/prophet/docs/trend_changepoints.html#adjusting-trend-flexibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:04:57.942259Z",
     "start_time": "2020-10-26T23:04:57.932259Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Default params:\\n')\n",
    "# Посмотрим, какое максимально возможное количество точек изменения тренда доступно в дефолтных параметрах \n",
    "print(f'n_changepoints = {m.n_changepoints}\\n')\n",
    "\n",
    "# Посмотрим, на каком периоде исторических данных профет будет выставлять точки\n",
    "print(f'changepoint_range = {m.changepoint_range}\\n')\n",
    "\n",
    "# Если изменения тренда являются чрезмерными или недостаточными, вы можете отрегулировать силу влияния changepoint_prior_scale. \n",
    "# По умолчанию этот параметр установлен на 0,05. Увеличение его сделает общую тенденцию более гибкой, уменьшение менее гибкой\n",
    "print(f'changepoint_prior_scale = {m.changepoint_prior_scale}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:04:58.693253Z",
     "start_time": "2020-10-26T23:04:57.945255Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = m.plot(forecast)\n",
    "\n",
    "# Изобразить эти автоматически обнаруженные точки излома можно с помощью функции *add_changepoints_to_plot()\n",
    "# Добавим сетку с точками изменения тренда (профет берет не все 25, а лишь отбирает не больше 25)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Что будет, если изменить **n_changepoints** (сделать показатель равным 4 или 100)?\n",
    "- Что конкретно менятся в модели, если изменить **changepoint_prior_scale** (сделать показатель равным 0.005, 0.025, 0.5)? \n",
    "- Для чего нам может потребоваться сделать **changepoint_range** равным 0.95?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = fp.Prophet(\n",
    "#     n_changepoints=100\n",
    "#     changepoint_prior_scale=0.0001\n",
    "#     changepoint_range=0.6\n",
    ")\n",
    "m.fit(data)\n",
    "\n",
    "future = m.make_future_dataframe(periods=45)\n",
    "\n",
    "forecast = m.predict(future)\n",
    "\n",
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сезонные компоненты\n",
    "\n",
    "\n",
    "[Почитать здесь](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html#fourier-order-for-seasonalities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Сезональные модели временных рядов делятся на два основных типа — аддитивные и мультипликативные.\n",
    "\n",
    "**$$y(t) = g(t) + s(t) + h(t) + \\varepsilon_t$$**\n",
    "**$$y(t) = g(t) * s(t) * h(t) * \\varepsilon_t$$**\n",
    "\n",
    "- Первый из них применяется в случаях, когда амплитуда сезонных колебаний приблизительно постоянна. Если же эта амплитуда заметно изменяется во времени (обычно возрастает), то строят мультипликативную модель.\n",
    "\n",
    "\n",
    "![image.png](https://www.researchgate.net/publication/348592737/figure/fig2/AS:981645804961802@1611054006728/Examples-for-multiplicative-and-additive-relationship-between-time-series-components.png)\n",
    "\n",
    "[Про мультипликативную сезональность](https://facebook.github.io/prophet/docs/multiplicative_seasonality.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_df(data.set_index('ds')[['y']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Default params:\\n')\n",
    "print(f'seasonality_mode = {m.seasonality_mode}\\n')\n",
    "\n",
    "print(f'seasonality_prior_scale = {m.seasonality_prior_scale}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:13:08.609130Z",
     "start_time": "2020-10-26T23:12:59.536131Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m_4 = fp.Prophet(\n",
    "#     seasonality_mode = 'multiplicative'\n",
    "#     seasonality_prior_scale = 0.1\n",
    ")\n",
    "\n",
    "m_4.fit(data)\n",
    "\n",
    "future = m_4.make_future_dataframe(periods=365*2)\n",
    "\n",
    "forecast = m_4.predict(future)\n",
    "fig6 = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:13:09.486184Z",
     "start_time": "2020-10-26T23:13:08.611135Z"
    }
   },
   "outputs": [],
   "source": [
    "fig6_5 = m_4.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эффекты праздников"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Для наших целей воспользуемся таблицей holidays_events среди [таблиц датасета](https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting/data)  - c ее помощью создадим датафрейм с праздниками под формат fbprophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = pd.read_csv('holidays_events.csv',parse_dates=['date'])\n",
    "holiday_df = holiday_df.rename(columns={'date' : 'ds','description':'holiday'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Default params:\\n')\n",
    "print(f'holidays_prior_scale = {m.holidays_prior_scale}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:16:16.505064Z",
     "start_time": "2020-10-26T23:16:07.617498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Посмотрим, что будет при учете праздников\n",
    "\n",
    "m_holidays = fp.Prophet(\n",
    "    holidays = holiday_df\n",
    "    ,holidays_prior_scale = 0.01\n",
    ")\n",
    "\n",
    "m_holidays.fit(data)\n",
    "\n",
    "future = m_holidays.make_future_dataframe(periods=365*2)\n",
    "\n",
    "forecast = m_holidays.predict(future)\n",
    "fig = m_holidays.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:16:17.846039Z",
     "start_time": "2020-10-26T23:16:16.506016Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = m_holidays.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Также важным параметром, влияющим на прогноз является <code>holidays_prior_scale</code>.  Обычно параметр изменяется в пределах [0.01, 10], при этом, чем выше этот параметр, тем меньше регуляризация, а значит сильнее выражены эффекты \"праздника\". Дефолтное значение параметра - 10 (отсутствие регуляризации)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление нового предиктора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Дополнительные регрессоры могут быть добавлены к линейной части модели с использованием add_regressor метода. \n",
    "\n",
    "- Столбец со значением регрессора должен присутствовать как во фреймах данных, так и в прогнозе. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Попробуем добавить дополнительный регрессор из прошлого занятия - Финансовый Индекс MSCI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_oil = pd.read_csv('oil.csv', parse_dates=['date'])\n",
    "df_oil = df_oil.rename(columns={\"date\": \"ds\",'dcoilwtico':'oil'}).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_vars = ['oil']\n",
    "\n",
    "data_x = data[['ds', 'y']].merge(df_oil[['ds']+exog_vars], \n",
    "                    on='ds', how='left')\n",
    "data_evaluation_x = data_evaluation[['ds', 'y']].merge(df_oil[['ds']+exog_vars],\n",
    "                                          on='ds', how='left')\n",
    "\n",
    "data_x[exog_vars] = data_x[exog_vars].interpolate(method='linear', axis=0,limit_direction='both')\n",
    "data_evaluation_x[exog_vars] = data_evaluation_x[exog_vars].interpolate(method='linear', axis=0,limit_direction='both')\n",
    "\n",
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = fp.Prophet()\n",
    "\n",
    "m.add_regressor('oil', mode='multiplicative')\n",
    "\n",
    "m.fit(data_x)\n",
    "\n",
    "future = m.make_future_dataframe(periods=validation_horizon)\n",
    "future = future.merge(data_evaluation_x[['ds','oil']],how='left', on = 'ds')\n",
    "\n",
    "forecast = m.predict(future)\n",
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.01, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [0.1, 10.0],\n",
    "    'seasonality_mode':['additive', 'multiplicative'],\n",
    "    'holidays_prior_scale':[0.1,10.0]\n",
    "}\n",
    "\n",
    "# Создадим все комбинации параметров\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "mapes = []  # будем записывать ошибки в этот лист \n",
    "\n",
    "# кросс валидация\n",
    "for params in tqdm(all_params):\n",
    "    m = fp.Prophet(**params).fit(data)  # Fit model with given params\n",
    "    df_cv = cross_validation(m, initial='730.25 days', period='180 days', horizon = '180 days', parallel=\"processes\")\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    mapes.append(df_p['mape'].values[0])\n",
    "\n",
    "# Find the best parameters\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['mape'] = mapes\n",
    "tuning_results.sort_values(by='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = all_params[tuning_results.sort_values(by='mape').index[0]]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- попробуем сделать тюнинг параметров с учетом внешнего фактора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.01, 0.5],\n",
    "    'seasonality_prior_scale': [0.1, 10.0],\n",
    "    'seasonality_mode':['additive', 'multiplicative'],\n",
    "    'holidays_prior_scale':[0.1,10.0]\n",
    "}\n",
    "\n",
    "# Создадим все комбинации параметров\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "mapes = []  # будем записывать ошибки в этот лист \n",
    "\n",
    "# кросс валидация\n",
    "for params in tqdm(all_params):\n",
    "    m = fp.Prophet(**params, holidays=holiday_df)  # Fit model with given params\n",
    "    m.add_regressor('oil', mode=params['seasonality_mode'])\n",
    "    m.fit(data_x)\n",
    "    df_cv = cross_validation(m, initial='730.25 days', period='180 days', horizon = '180 days', parallel=\"processes\")\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    mapes.append(df_p['mape'].values[0])\n",
    "\n",
    "# Find the best parameters\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['mape'] = mapes\n",
    "tuning_results.sort_values(by='mape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Видно, что с внешним фактором результат получается сильно лучше. Включим его в модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим, что будет при учете праздников\n",
    "\n",
    "m_holidays = fp.Prophet(\n",
    "    holidays = holiday_df,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "m_holidays.add_regressor('oil', mode='multiplicative')\n",
    "\n",
    "m_holidays.fit(data_x)\n",
    "\n",
    "future = m_holidays.make_future_dataframe(periods=validation_horizon)\n",
    "future = future.merge(data_evaluation_x[['ds','oil']],how='left', on = 'ds')\n",
    "\n",
    "\n",
    "forecast = m_holidays.predict(future)\n",
    "fig = m_holidays.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m_holidays, forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем формат для джойна табличек\n",
    "data_evaluation['ds'] = pd.to_datetime(data_evaluation['ds'])\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "data_w_error = data_evaluation.merge(forecast[['ds','yhat']], on = ['ds'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем ошибку\n",
    "data_w_error['mape'] = abs(data_w_error['y'] - data_w_error['yhat'])/data_w_error['y']\n",
    "print('Prophet MAPE is: ', np.mean(data_w_error[data_w_error['ds']>max(data['ds'])]['mape']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_error.columns=['ds','y', 'forecast_p','mape']\n",
    "data_w_error.loc[data_w_error['ds']<=max(data['ds']),'forecast_p'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predicted_class_15 = pd.read_csv('data_predicted_class_15.csv')\n",
    "data_sarima_prophet = data_predicted_class_15.merge(data_w_error[['forecast_p']], left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_df(data_sarima_prophet[['y_validation','forecast_s','forecast_p']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Давайте сравним модели SARIMAX и Prophet:\n",
    "    - Model SARIMA MAPE is ..\n",
    "    - **Model Prophet MAPE is ..**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение и обработка исходных данных.\n",
    "sales_train_raw = pd.read_csv('train_data.csv', parse_dates=['date'])\n",
    "\n",
    "sales_train = pd.pivot_table(sales_train_raw, index='date', values='sales', aggfunc=sum).reset_index()\n",
    "sales_train.columns = ['ds', 'y']\n",
    "\n",
    "validation_horizon = 180\n",
    "data = sales_train[sales_train['ds']<=(max(sales_train['ds']) - datetime.timedelta(days=validation_horizon))]\n",
    "data_evaluation = sales_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df['holiday_flag']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def add_datepart(dff, fldname, holidays, lags=7, drop=True, errors=\"raise\"):\n",
    "    df = dff.copy()\n",
    "    fld=df[fldname]\n",
    "    targ_pre = re.sub('ds', '', fldname)\n",
    "    \n",
    "    # date attributes\n",
    "    attr = ['Month', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    for n in attr: \n",
    "        df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "    df['Week']=(df['Dayofyear']/7).apply(np.ceil)\n",
    "    \n",
    "    df['Is_week_end'] = df['Dayofweek'].apply(lambda x: 1 if x in [5,6] else 0)\n",
    "    \n",
    "    # lags\n",
    "    for lag in range(1,lags+1):\n",
    "        df['y_lag_'+str(lag)] = df['y'].shift(lag)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # diff\n",
    "    df['y_diff_1'] = df['y'].diff()\n",
    "    df['y_diff_2'] = df['y'].diff(2)\n",
    "    df['y_diff_7'] = df['y'].diff(7)    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    # moving average\n",
    "    df['y_ma_mean'] = df['y'].rolling(7).mean()\n",
    "    df['y_ma_std'] = df['y'].rolling(7).std()\n",
    "    df = df.dropna()    \n",
    "    \n",
    "    #holidays\n",
    "    df = df.merge(holidays[['ds','holiday_flag']], on='ds', how='left')\n",
    "    df['holiday_flag'] = df['holiday_flag'].fillna(0)\n",
    "    \n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "        \n",
    "data = add_datepart(data_evaluation, 'ds',holiday_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(a,n): \n",
    "    return a[:n].copy(), a[n:].copy()\n",
    "\n",
    "n_trn = int(len(data)-180)\n",
    "x = data.drop('y',axis = 1)\n",
    "y = data[['y']]\n",
    "X_train, X_test = split_vals(x, n_trn)\n",
    "y_train, y_test = split_vals(y, n_trn)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 800, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [1, 'sqrt',0.5]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,3,5]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, np.ravel(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фит модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "\n",
    "foreacst_rf = best_random.predict(X_test)\n",
    "mape_err = np.mean(abs(foreacst_rf-y_test['y'])/y_test['y'])\n",
    "\n",
    "print(f'MAPE: {mape_err}')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast_rf_df = pd.DataFrame(foreacst_rf)\n",
    "forecast_rf_df.rename(columns = {0:'foreacst_rf'},inplace = True)\n",
    "forecast_rf_df.index=range(len(data_evaluation)-180,len(data_evaluation))\n",
    "forecast_rf_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predicted_class_15 = pd.read_csv('data_predicted_class_15.csv')\n",
    "\n",
    "data_sarima_prophet_rf = data_predicted_class_15[['y_validation','forecast_s']].merge(\n",
    "    data_w_error[['forecast_p']], left_index=True, right_index=True).merge(\n",
    "    forecast_rf_df, how='left',left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sarima_prophet_rf['foreacst_rf']=data_sarima_prophet_rf['foreacst_rf'].shift(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_df(data_sarima_prophet_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Давайте сравним модели SARIMAX и Prophet:\n",
    "    - Model SARIMA MAPE is ...\n",
    "    - Model Prophet MAPE is ...\n",
    "    - **Model Random Forest is ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
